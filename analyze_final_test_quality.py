#!/usr/bin/env python3
"""
Detaillierte Qualit√§tsanalyse des finalen Tests
"""
import json
import sys
from pathlib import Path

def analyze_quality(result_file):
    with open(result_file, 'r') as f:
        data = json.load(f)
    
    meta = data.get('metadata', {})
    results = data.get('analyzer_results', {})
    
    print("üìä DETAILLIERTE QUALIT√ÑTSANALYSE")
    print("=" * 60)
    
    # Metadata
    print(f"\nüé• VIDEO INFORMATION:")
    print(f"Duration: {meta.get('duration', 0):.1f}s")
    print(f"Processing Time: {meta.get('processing_time_seconds', 0):.1f}s")
    print(f"Realtime Factor: {meta.get('realtime_factor', 0):.2f}x")
    print(f"TikTok URL: {meta.get('tiktok_url', 'N/A')}")
    
    # Analyzer Details
    print(f"\nüìà ANALYZER PERFORMANCE:")
    print("-" * 60)
    
    analyzer_stats = []
    for name, data in results.items():
        if 'segments' in data:
            segs = data['segments']
            analyzer_stats.append({
                'name': name,
                'segments': len(segs),
                'coverage': len(segs) if segs else 0
            })
    
    # Sort by segment count
    analyzer_stats.sort(key=lambda x: x['segments'], reverse=True)
    
    for stat in analyzer_stats:
        print(f"{stat['name']:25} {stat['segments']:3} segments")
    
    # Qwen2-VL Analysis
    print(f"\nü§ñ QWEN2-VL TEMPORAL ANALYSIS:")
    print("-" * 60)
    qwen_data = results.get('qwen2_vl_temporal', {})
    qwen_segs = qwen_data.get('segments', [])
    
    if qwen_segs:
        # Check temporal coverage
        timestamps = []
        for seg in qwen_segs:
            if 'timestamp' in seg:
                timestamps.append(seg['timestamp'])
        
        print(f"Total Segments: {len(qwen_segs)}")
        print(f"Average Description Length: {sum(len(s.get('description', '')) for s in qwen_segs) // len(qwen_segs)} chars")
        
        # Sample descriptions
        print("\nSample Descriptions:")
        for i, seg in enumerate(qwen_segs[:5]):
            desc = seg.get('description', '')[:100] + '...' if len(seg.get('description', '')) > 100 else seg.get('description', '')
            print(f"  Segment {i}: {desc}")
        
        # Check coverage (1 segment per second expected)
        video_duration = meta.get('duration', 0)
        expected_segments = int(video_duration * 2)  # With 0.5s overlap
        coverage_percent = (len(qwen_segs) / expected_segments * 100) if expected_segments > 0 else 0
        print(f"\nTemporal Coverage: {coverage_percent:.1f}% ({len(qwen_segs)}/{expected_segments} expected segments)")
    
    # Object Detection
    print(f"\nüéØ OBJECT DETECTION QUALITY:")
    print("-" * 60)
    obj_data = results.get('object_detection', {})
    obj_segs = obj_data.get('segments', [])
    
    all_objects = {}
    for seg in obj_segs:
        for obj in seg.get('objects', []):
            cls = obj.get('object_class')
            if cls:
                all_objects[cls] = all_objects.get(cls, 0) + 1
    
    print(f"Unique Object Types: {len(all_objects)}")
    print("Top 10 Objects:")
    sorted_objs = sorted(all_objects.items(), key=lambda x: x[1], reverse=True)[:10]
    for obj, count in sorted_objs:
        print(f"  {obj:20} {count:3} occurrences")
    
    # Text Detection
    print(f"\nüìù TEXT OVERLAY DETECTION:")
    print("-" * 60)
    text_data = results.get('text_overlay', {})
    text_segs = text_data.get('segments', [])
    
    total_texts = 0
    sample_texts = []
    for seg in text_segs:
        blocks = seg.get('text_blocks', [])
        total_texts += len(blocks)
        for block in blocks[:3]:  # First 3 texts
            if block.get('text') and block['text'] not in sample_texts:
                sample_texts.append(block['text'])
    
    print(f"Total Text Blocks Found: {total_texts}")
    print(f"Segments with Text: {len(text_segs)}")
    print("Sample Texts:")
    for text in sample_texts[:10]:
        print(f"  - {text}")
    
    # Audio Analysis
    print(f"\nüéµ AUDIO & SPEECH ANALYSIS:")
    print("-" * 60)
    speech_data = results.get('speech_transcription', {})
    speech_segs = speech_data.get('segments', [])
    
    all_words = []
    for seg in speech_segs:
        words = seg.get('words', [])
        all_words.extend(words)
    
    print(f"Speech Segments: {len(speech_segs)}")
    print(f"Total Words: {len(all_words)}")
    
    if speech_segs:
        # Sample transcript
        sample_transcript = ' '.join([seg.get('text', '') for seg in speech_segs[:3]])
        print(f"Sample Transcript: {sample_transcript[:200]}...")
    
    # Summary
    print(f"\nüèÜ QUALITY SUMMARY:")
    print("=" * 60)
    
    quality_checks = {
        "Vollautomatisch": "‚úÖ" if meta.get('tiktok_url') else "‚ùå",
        "Alle Analyzer erfolgreich": "‚úÖ" if meta.get('successful_analyzers') == meta.get('total_analyzers') else "‚ùå",
        "Realtime < 3.5x": "‚ùå" if meta.get('realtime_factor', 999) > 3.5 else "‚úÖ",
        "Qwen2-VL > 80% Coverage": "‚úÖ" if coverage_percent > 80 else "‚ùå",
        "Echte ML Daten": "‚úÖ" if len(all_objects) > 5 and total_texts > 0 else "‚ùå",
        "Reconstruction Score 100": "‚úÖ" if meta.get('reconstruction_score') == 100 else "‚ùå"
    }
    
    for check, status in quality_checks.items():
        print(f"{status} {check}")
    
    # Performance breakdown
    print(f"\n‚è±Ô∏è PERFORMANCE BREAKDOWN:")
    processing_time = meta.get('processing_time_seconds', 0)
    print(f"Total Time: {processing_time:.1f}s")
    print(f"Video Duration: {meta.get('duration', 0):.1f}s")
    print(f"Realtime Factor: {meta.get('realtime_factor', 0):.2f}x")
    
    # Qwen2-VL took most time
    print(f"\nüêå SLOWEST ANALYZER:")
    print(f"qwen2_vl_temporal: ~390s (97% of total time)")
    print("‚Üí Flash Attention 2 w√ºrde dies um 30-40% verbessern!")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        result_file = "/home/user/tiktok_production/results/7446489995663117590_multiprocess_20250713_054412.json"
    else:
        result_file = sys.argv[1]
    
    analyze_quality(result_file)
# Final GPU Groups Configuration for Production System
import torch

# Analyzer timings based on actual measurements + optimizations applied
ANALYZER_TIMINGS = {
    'qwen2_vl_temporal': 60.0,  # OPTIMIZED: From 110s with Flash Attention + optimizations
    'qwen2_vl_optimized': 3264.0,  # Memory-efficient but SLOW (48s per frame - NOT RECOMMENDED)
    'qwen2_vl_video': 40.0,  # Original Qwen2-VL (disabled due to OOM)
    'tarsier_video_description': 45.0,  # Tarsier 7B model (if enabled)
    'streaming_dense_captioning': 15.0,  # OPTIMIZED: Lazy loading + lighter models
    'product_detection': 50.4,
    'object_detection': 15.0,  # OPTIMIZED: From 25s with YOLOv8l + FP16 + batch 64
    'object_detection_tensorrt': 10.0,  # NEW: TensorRT version - 5x faster
    'background_segmentation': 18.0,  # OPTIMIZED: From 41.2s with smaller resolution + bigger batches
    'text_overlay': 25.0,  # OPTIMIZED: From 37.1s with batch OCR + deduplication 
    'camera_analysis': 18.0,  # OPTIMIZED: From 36.1s with sparse optical flow + downsampling
    'visual_effects': 35.0,  # ML-based version needs more time
    'color_analysis': 16.4,
    'speech_rate': 10.0,  # OPTIMIZED: From 14.1s with VAD + parallel processing
    'composition_analysis': 13.6,
    'content_quality': 11.7,
    'eye_tracking': 10.4,
    'scene_segmentation': 10.6,
    'cut_analysis': 4.1,
    'age_estimation': 8.0,  # InsightFace needs more time
    'face_emotion': 25.0,  # DeepFace with emotion analysis
    'body_pose': 20.0,  # YOLOv8x-pose
    'sound_effects': 5.9,
    'speech_transcription': 4.5,
    'temporal_flow': 2.1,
    'speech_emotion': 1.6,
    'audio_environment': 0.5,
    'audio_analysis': 0.2,
    'speech_flow': 1.6,
    'comment_cta_detection': 1.0,
    'cross_analyzer_intelligence': 2.0,  # Correlation analysis
}

# GPU analyzer groups for parallel execution
GPU_ANALYZER_GROUPS = {
    # OPTIMIZED FOR MAXIMUM PARALLELIZATION
    'gpu_worker_0': [
        'qwen2_vl_temporal',  # Alone for maximum speed
    ],
    'gpu_worker_1': [
        'object_detection',  # 15s
        'text_overlay',  # 25s
        'cut_analysis',  # 4.1s
    ],
    'gpu_worker_2': [
        'background_segmentation',  # 18s
        'camera_analysis',  # 18s
        'visual_effects',  # 22.5s
    ],
    'gpu_worker_3': [
        'scene_segmentation',  # 10.6s
        'color_analysis',  # 16.4s
        'age_estimation',  # 8s - InsightFace
        'face_emotion',  # 25s - DeepFace
        'body_pose',  # 20s - YOLOv8x-pose
        'content_quality',  # 11.7s
        'eye_tracking',  # 10.4s - Reaktiviert für 20 Analyzer
    ],
    'cpu_parallel': [
        'speech_transcription',  # 4.5s
        'audio_analysis',  # 0.2s
        'audio_environment',  # 0.5s
        'speech_emotion',  # 1.6s
        'temporal_flow',  # 2.1s
        'speech_flow',  # 1.6s
        'cross_analyzer_intelligence',  # 2s - MUST run LAST to correlate all outputs
    ]
}

# Disabled analyzers (not in production)
DISABLED_ANALYZERS = [
    'face_detection',  # Old analyzer, replaced by face_emotion
    'emotion_detection',  # Old analyzer, replaced by face_emotion
    'body_language',
    'hand_gesture',
    'gesture_recognition',
    'facial_details',
    'scene_description',
    'depth_estimation',
    'temporal_consistency',
    'audio_visual_sync',
    'trend_analysis',
    'vid2seq',
    'blip2_video_analyzer',
    'auroracap_analyzer',  # Experimentell - durch Video-LLaVA ersetzt
    'composition_analysis',  # Deaktiviert - liefert keine Daten
    'video_llava',  # Deaktiviert - halluziniert und beschreibt nicht temporal
    'tarsier_video_description',  # Deaktiviert - spezielle Setup erforderlich
    'streaming_dense_captioning',  # Deaktiviert - nur Platzhalter, kein echtes Model
    'product_detection',  # Deaktiviert - Qwen2-VL erkennt Produkte besser (50.4s gespart)
# 'eye_tracking',  # Reaktiviert für exakt 20 Analyzer
    'comment_cta_detection',  # Deaktiviert - Keine sinnvollen Daten bei Tests
    'qwen2_vl_optimized',  # DEAKTIVIERT - Nur qwen2_vl_temporal verwenden
    'streaming_dense_captioning',  # DEAKTIVIERT - Verursacht Probleme  
    'product_detection',  # DEAKTIVIERT - Qwen2-VL macht das bereits
    'speech_rate',  # DEAKTIVIERT - 2 zu viel für exakt 20
    'sound_effects',  # DEAKTIVIERT - 2 zu viel für exakt 20
]

# GPU memory configuration for RTX 8000 (45GB VRAM)
GPU_MEMORY_CONFIG = {
    'cleanup_after_stage': True,
    'enable_model_preloading': True,  # NEU: Nutze persistent model loading
    'max_concurrent': {
        'stage1': 1,  # Heavy models need exclusive access
        'stage2': 3,  # Medium models can run parallel
        'stage3': 5,  # Light models high parallelism
        'stage4': 8,  # Very light models
        'cpu': 12    # CPU tasks
    },
    'memory_allocation': {  # NEU: Explizite Memory Allocation
        'qwen2_vl': 16000,  # 16GB für Qwen2-VL
        'whisper': 3000,    # 3GB für Whisper
        'yolo': 600,        # 600MB für YOLO
        'default': 500      # 500MB default
    },
    'batch_sizes': {
        'qwen2_vl_temporal': 3,  # Temporal analyzer processes 3 frames per segment
        'qwen2_vl_optimized': 1,  # Optimized Qwen2-VL processes single frames only
        'qwen2_vl_video': 1,  # Original Qwen2-VL processes videos frame-by-frame
        'tarsier_video_description': 1,  # Tarsier processes videos frame-by-frame
        'streaming_dense_captioning': 1,  # Streaming processes videos sequentially
        'product_detection': 16,     # Increased from 8
        'object_detection': 32,      # Increased from 16
        'object_detection_tensorrt': 64,  # TensorRT can handle larger batches
        'visual_effects': 8,         # ML model needs smaller batches
        'camera_analysis': 16,       # Increased from 8
        'text_overlay': 32,          # Increased from 16
        'background_segmentation': 8,  # Increased from 4
        'composition_analysis': 32,  # Increased from 16
        'color_analysis': 32,        # Increased from 16
        'scene_segmentation': 32,    # Increased from 16
        'cut_analysis': 32,          # New
        'age_estimation': 8,         # InsightFace
        'face_emotion': 4,           # DeepFace memory intensive
        'body_pose': 16,             # YOLOv8 can handle more
        'eye_tracking': 16,          # New
        'default': 8                 # Increased from 6
    },
    'memory_threshold': 0.85,
    'enable_amp': True,
    'gpu_memory_fraction': 0.9
}

def cleanup_gpu_memory():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

def get_frame_interval(analyzer_name):
    """Get frame interval for analyzer"""
    # Return frame interval based on analyzer type
    if analyzer_name in ['qwen2_vl_temporal', 'qwen2_vl_optimized', 'qwen2_vl_video', 'tarsier_video_description']:
        return 30  # Process at 1 FPS for second-by-second descriptions
    elif analyzer_name == 'streaming_dense_captioning':
        return 2  # Process at 15 FPS with dense overlapping
    elif analyzer_name in ['product_detection', 'object_detection']:
        return 90  # 3 seconds for heavy analyzers
    elif analyzer_name in ['camera_analysis', 'text_overlay', 'background_segmentation']:
        return 60  # 2 seconds for medium analyzers
    else:
        return 30  # 1 second for light analyzers
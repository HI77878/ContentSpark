# TikTok Video Analysis System - Vollst√§ndige Dokumentation

## üèóÔ∏è System-Architektur

Dieses hochoptimierte System analysiert TikTok-Videos mit 17 ML-basierten Analyzern und erreicht **nahezu Echtzeit-Performance** (0.8-1.5x realtime) durch fortschrittliche GPU-Optimierungen.

### Gesamtarchitektur
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           TikTok Video Analysis System                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Input: TikTok URL oder Video-Datei                                        ‚îÇ
‚îÇ     ‚Üì                                                                       ‚îÇ
‚îÇ  [TikTok Downloader] ‚Üí Video-Datei (MP4)                                   ‚îÇ
‚îÇ     ‚Üì                                                                       ‚îÇ
‚îÇ  [FastAPI Server] (Port 8003)                                              ‚îÇ
‚îÇ     ‚Üì                                                                       ‚îÇ
‚îÇ  [Cached GPU Executor] ‚Üê Model Caching f√ºr 80-90% Speedup                 ‚îÇ
‚îÇ     ‚Üì                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Worker Processes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ  ‚îÇ  GPU Worker 0:    ‚îÇ  GPU Worker 1:    ‚îÇ  GPU Worker 2:  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  - Qwen2-VL       ‚îÇ  - Object Det.    ‚îÇ  - Scene Seg.   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ    (16GB VRAM)     ‚îÇ  - Text Overlay   ‚îÇ  - Color Anal.  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ                   ‚îÇ  - Background     ‚îÇ  - Body Pose    ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ                   ‚îÇ  - Camera Anal.   ‚îÇ  - Age/Quality  ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ     ‚Üì                                                                       ‚îÇ
‚îÇ  [Result Aggregation] + [Output Normalization]                             ‚îÇ
‚îÇ     ‚Üì                                                                       ‚îÇ
‚îÇ  Output: Comprehensive JSON Analysis (2-3MB)                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Datenfluss vom Input bis Output
1. **Input**: TikTok URL oder lokale Video-Datei
2. **Download**: TikTok-Videos werden mit yt-dlp heruntergeladen
3. **Frame Extraction**: Videos werden in Frames zerlegt (verschiedene Sampling-Raten)
4. **GPU Worker Distribution**: Frames werden an spezialisierte GPU-Worker verteilt
5. **Model Caching**: ML-Modelle bleiben zwischen Analysen im GPU-Speicher
6. **Parallel Processing**: 17 Analyzer laufen gleichzeitig auf 3 GPU-Workern + CPU-Pool
7. **Result Aggregation**: Ergebnisse werden normalisiert und zusammengef√ºhrt
8. **JSON Output**: 2-3MB detaillierte Analyse mit Frame-by-Frame Daten

### GPU-Optimierungen und deren Funktionsweise

#### Model Caching System
```python
# Automatisches Model Caching
# Erste Analyse: Modelle laden von Disk ‚Üí GPU (langsamer)
# Folgende Analysen: Modelle aus GPU-Cache (80-90% schneller)

class PersistentModelManager:
    def get_analyzer(self, name, analyzer_class):
        if name not in self.cached_models:
            # Lade Modell einmalig
            model = analyzer_class()
            model.eval()  # Optimization mode
            model.cuda()  # GPU placement
            self.cached_models[name] = model
        return self.cached_models[name]  # Wiederverwendung
```

#### GPU Worker Verteilung
- **Worker 0**: Exklusiv f√ºr Qwen2-VL (ben√∂tigt 16GB VRAM allein)
- **Worker 1**: Visuelle Analyse (Object Detection, Text, Background, Camera)
- **Worker 2**: Detail-Analyse (Scene, Color, Pose, Age, Quality)
- **CPU Pool**: Audio-Analyse parallel (Whisper, Librosa, Wav2Vec2)

#### Memory Pool Optimierung
```bash
# PyTorch CUDA Allocator Konfiguration
export PYTORCH_CUDA_ALLOC_CONF='max_split_size_mb:512,expandable_segments:True,garbage_collection_threshold:0.9'
# Reduziert GPU Memory Fragmentierung um 60%
```

## üìÅ Verzeichnisstruktur

```
tiktok_production/
‚îú‚îÄ‚îÄ analyzers/                    # 130+ Analyzer-Dateien
‚îÇ   ‚îú‚îÄ‚îÄ base_analyzer.py         # Basis-Klasse f√ºr alle Analyzer
‚îÇ   ‚îú‚îÄ‚îÄ gpu_batch_*.py           # GPU-optimierte Analyzer
‚îÇ   ‚îú‚îÄ‚îÄ qwen2_vl_video_analyzer.py  # Hauptmodell f√ºr Video-Verst√§ndnis
‚îÇ   ‚îî‚îÄ‚îÄ [weitere 127 Dateien]
‚îú‚îÄ‚îÄ api/                         # FastAPI Server
‚îÇ   ‚îú‚îÄ‚îÄ stable_production_api_multiprocess.py  # PRODUCTION API (verwende diese!)
‚îÇ   ‚îî‚îÄ‚îÄ archived_apis_20250711/  # Archivierte API-Versionen
‚îú‚îÄ‚îÄ configs/                     # Konfigurationsdateien
‚îÇ   ‚îú‚îÄ‚îÄ gpu_groups_config.py     # GPU-Worker Verteilung & Deaktivierte Analyzer
‚îÇ   ‚îú‚îÄ‚îÄ performance_config.py    # Frame-Sampling & Batch-Gr√∂√üen
‚îÇ   ‚îî‚îÄ‚îÄ system_config.py         # System-weite Einstellungen
‚îú‚îÄ‚îÄ utils/                       # Utilities & GPU-Management
‚îÇ   ‚îú‚îÄ‚îÄ multiprocess_gpu_executor_registry_cached.py  # Cached GPU Executor
‚îÇ   ‚îú‚îÄ‚îÄ persistent_model_manager.py                   # Model Caching System
‚îÇ   ‚îú‚îÄ‚îÄ qwen2_vl_batcher.py      # Qwen2-VL Batch-Optimierung
‚îÇ   ‚îî‚îÄ‚îÄ gpu_monitor.py           # GPU-Monitoring Tools
‚îú‚îÄ‚îÄ mass_processing/             # Batch-Verarbeitung
‚îÇ   ‚îú‚îÄ‚îÄ tiktok_downloader.py     # TikTok Video Downloader
‚îÇ   ‚îú‚îÄ‚îÄ bulk_processor.py        # Bulk Processing CLI
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt         # Mass Processing Dependencies
‚îú‚îÄ‚îÄ results/                     # Analyse-Ergebnisse (JSON)
‚îú‚îÄ‚îÄ logs/                        # System-Logs
‚îú‚îÄ‚îÄ backups/                     # System-Backups f√ºr Rollback
‚îú‚îÄ‚îÄ docs/                        # Technische Dokumentation
‚îú‚îÄ‚îÄ fix_ffmpeg_env.sh           # KRITISCH: FFmpeg & GPU Environment Setup
‚îú‚îÄ‚îÄ start_mps.sh                # NVIDIA MPS Setup (optional, f√ºr max. Performance)
‚îú‚îÄ‚îÄ ml_analyzer_registry_complete.py  # Zentrale Analyzer-Registry
‚îú‚îÄ‚îÄ test_optimizations.py       # Performance-Tests
‚îú‚îÄ‚îÄ monitoring_dashboard.py     # Echtzeit-GPU-Monitoring
‚îî‚îÄ‚îÄ README_COMPLETE.md          # Diese Datei
```

### Wichtige Dateien im Detail

**KRITISCHE DATEIEN (niemals l√∂schen):**
- `fix_ffmpeg_env.sh` - Behebt FFmpeg pthread Probleme, MUSS vor jedem Start geladen werden
- `ml_analyzer_registry_complete.py` - Registry aller 30+ Analyzer (17 aktiv)
- `api/stable_production_api_multiprocess.py` - Production API mit GPU-Optimierungen

**KONFIGURATIONS-DATEIEN:**
- `configs/gpu_groups_config.py` - Definiert welche Analyzer auf welchem GPU-Worker laufen
- `configs/performance_config.py` - Frame-Sampling Raten, Batch-Gr√∂√üen pro Analyzer
- `utils/multiprocess_gpu_executor_registry_cached.py` - GPU Executor mit Model Caching

## ü§ñ Die 17 Analyzer im Detail

### GPU Worker 0 (Exklusiv - 16GB VRAM erforderlich)

#### `qwen2_vl_temporal` - Video-Verst√§ndnis
- **Modell**: Qwen2-VL-7B-Instruct (Alibaba)
- **Funktion**: Temporale Video-Analyse, Szenen-Beschreibung
- **Input**: 16 Frames pro Segment (2-Sekunden Segmente)
- **Output**: Detaillierte Beschreibungen mit zeitlichen Zusammenh√§ngen
- **VRAM**: 16GB
- **Laufzeit**: 60s (optimiert von 110s)
- **Beispiel-Output**:
```json
{
  "segment_id": "qwen_temporal_0",
  "start_time": 0.0,
  "end_time": 2.0,
  "description": "Eine Person zeigt energetisch ein Produkt in die Kamera, w√§hrend sich im Hintergrund ein moderner Raum mit warmer Beleuchtung befindet.",
  "confidence": 0.95
}
```

### GPU Worker 1 (Visuelle Analyse - 8-10GB VRAM)

#### `object_detection` - Objekterkennung
- **Modell**: YOLOv8x (Ultralytics)
- **Funktion**: Erkennt 80 COCO-Objektklassen + TikTok-spezifische Objekte
- **Input**: Jeden 10. Frame (dense sampling)
- **Output**: Bounding Boxes mit Confidence Scores
- **VRAM**: 3-4GB
- **Laufzeit**: 15s (optimiert von 25s)
- **Beispiel-Output**:
```json
{
  "timestamp": 1.5,
  "objects": [
    {
      "object_class": "person",
      "confidence_score": 0.952,
      "bounding_box": {"x": 252, "y": 554, "width": 434, "height": 1326},
      "position": "middle-center"
    }
  ]
}
```

#### `text_overlay` - Text-Erkennung
- **Modell**: EasyOCR (optimiert f√ºr TikTok-Untertitel)
- **Funktion**: Erkennt Untertitel, Overlays, eingeblendete Texte
- **Input**: Jeden 30. Frame + Bewegungserkennungs-basiert
- **Output**: Erkannter Text mit Position und Zeitstempel
- **VRAM**: 2-3GB
- **Laufzeit**: 25s (optimiert von 37s)

#### `background_segmentation` - Hintergrund-Trennung
- **Modell**: SegFormer (NVIDIA)
- **Funktion**: Semantische Segmentierung von Vorder-/Hintergrund
- **Input**: Jeden 15. Frame
- **Output**: Segmentierungsmasken + Szenen-Klassifikation
- **VRAM**: 2-3GB
- **Laufzeit**: 18s (optimiert von 41s)

#### `camera_analysis` - Kamera-Bewegung
- **Modell**: Optical Flow + Custom CV
- **Funktion**: Erkennt Zoom, Pan, Tilt, Stabilit√§t
- **Input**: Dense Frame Sampling (jeden 5. Frame)
- **Output**: Kamera-Bewegungstypen mit Intensit√§t
- **VRAM**: 1-2GB
- **Laufzeit**: 18s (optimiert von 36s)

### GPU Worker 2 (Detail-Analyse - 5-7GB VRAM)

#### `scene_segmentation` - Szenen-Erkennung
- **Modell**: Custom Similarity Detection
- **Funktion**: Erkennt Szenenwechsel und √úberg√§nge
- **Output**: Szenen-Grenzen mit √úbergangstyp

#### `color_analysis` - Farbanalyse
- **Modell**: K-Means + Color Space Analysis
- **Funktion**: Extrahiert Farbpaletten, Farbstimmung
- **Output**: Dominante Farben, Farbtemperatur, Stimmung

#### `body_pose` - K√∂rperhaltung
- **Modell**: YOLOv8x-Pose
- **Funktion**: Pose-Estimation, Gesten-Erkennung
- **Output**: Skelett-Keypoints, Gesten-Labels

#### `age_estimation` - Alters-/Geschlechtserkennung
- **Modell**: InsightFace
- **Funktion**: Demographie-Analyse sichtbarer Personen
- **Output**: Gesch√§tztes Alter und Geschlecht

#### `content_quality` - Qualit√§tsbewertung
- **Modell**: CLIP + Custom Metrics
- **Funktion**: Technische und √§sthetische Qualit√§t
- **Output**: Qualit√§ts-Scores (0-1)

#### `eye_tracking` - Blickverfolgung
- **Modell**: MediaPipe Iris
- **Funktion**: Blickrichtung und Aufmerksamkeit
- **Output**: Gaze-Vektor, Blickziele

#### `cut_analysis` - Schnitterkennung
- **Modell**: Frame Difference + ML
- **Funktion**: Erkennt Schnitte und √úberg√§nge
- **Output**: Cut-Punkte mit √úbergangstyp

### CPU Workers (Audio/Metadata - Parallel)

#### `speech_transcription` - Spracherkennung
- **Modell**: Whisper Large V3
- **Funktion**: Speech-to-Text mit Spracherkennung
- **Output**: Transkript mit Zeitstempeln, Sprache
- **Laufzeit**: 4.5s

#### `audio_analysis` - Audio-Analyse
- **Modell**: Librosa + Custom Features
- **Funktion**: Tempo, Pitch, Spektral-Features
- **Output**: Audio-Features, Musik-Klassifikation

#### `audio_environment` - Umgebungsger√§usche
- **Modell**: YAMNet + Custom
- **Funktion**: Klassifiziert Hintergrundger√§usche
- **Output**: Umgebungstyp (indoor/outdoor/etc.)

#### `speech_emotion` - Sprach-Emotion
- **Modell**: Wav2Vec2 + Emotion Classifier
- **Funktion**: Emotionen aus Sprachmelodie
- **Output**: Emotionen (happy, sad, excited, etc.)

#### `temporal_flow` - Narrative Analyse
- **Modell**: Custom NLP + Sequence Analysis
- **Funktion**: Erz√§hlstruktur und -fluss
- **Output**: Narrative Segmente, Story Arc

#### `speech_flow` - Sprachfluss
- **Modell**: VAD + Prosody Analysis
- **Funktion**: Sprechpausen, Betonung, Rhythmus
- **Output**: Speech Patterns, Emphasis Points

## üöÄ Installation & Setup

### Systemanforderungen
- **OS**: Ubuntu 22.04 LTS
- **GPU**: NVIDIA RTX 8000 (44.5GB VRAM) oder vergleichbar (min. 24GB)
- **CPU**: Multi-Core (min. 8 Threads f√ºr optimale Performance)
- **RAM**: 40GB+ (f√ºr Model Loading und Frame Processing)
- **Storage**: 100GB+ freier Speicherplatz
- **CUDA**: 12.4+ mit kompatiblen Treibern
- **Python**: 3.10+ (empfohlen: 3.10.12)

### Schritt-f√ºr-Schritt Installation

#### 1. System-Dependencies
```bash
# Update System
sudo apt update && sudo apt upgrade -y

# Install essential packages
sudo apt install -y python3-pip python3-venv git curl wget
sudo apt install -y ffmpeg libsm6 libxext6 libxrender-dev
sudo apt install -y nvidia-cuda-toolkit  # Falls noch nicht installiert
```

#### 2. Repository Setup
```bash
# Clone Repository
git clone [REPOSITORY_URL] tiktok_production
cd tiktok_production

# Erstelle Virtual Environment (empfohlen)
python3 -m venv venv
source venv/bin/activate
```

#### 3. Python Dependencies Installation
```bash
# Install alle Requirements
pip install -r requirements.txt

# Wichtige Packages werden installiert:
# - torch>=2.0.0 (mit CUDA Support)
# - transformers>=4.30.0
# - fastapi>=0.100.0
# - opencv-python>=4.8.0
# - whisper>=1.1.10
# - ultralytics>=8.0.0
# - [weitere 50+ Dependencies]
```

#### 4. GPU-Konfiguration
```bash
# Verifiziere GPU
nvidia-smi

# Setup GPU Environment (KRITISCH!)
source fix_ffmpeg_env.sh

# Teste CUDA-Verf√ºgbarkeit
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

#### 5. Model Downloads (automatisch beim ersten Start)
```bash
# Modelle werden automatisch heruntergeladen:
# - Qwen2-VL-7B-Instruct (~14GB)
# - YOLOv8x Weights (~131MB)
# - Whisper Large V3 (~1.5GB)
# - Weitere Modelle (~5GB total)
# 
# Erster Start dauert 15-30 Minuten f√ºr Downloads
```

#### 6. Erste Verifikation
```bash
# Start API
python3 api/stable_production_api_multiprocess.py &

# Warte 30-60 Sekunden f√ºr Model Loading
sleep 60

# Health Check
curl http://localhost:8003/health

# Sollte ausgeben:
# {"status": "healthy", "active_analyzers": 17, "gpu_available": true}
```

## üîß Konfiguration

### Alle Config-Dateien erkl√§rt

#### `configs/gpu_groups_config.py` - GPU Worker Distribution
```python
# Definiert welche Analyzer auf welchem GPU-Worker laufen
GPU_ANALYZER_GROUPS = {
    'gpu_worker_0': ['qwen2_vl_temporal'],  # Exklusiv
    'gpu_worker_1': ['object_detection', 'text_overlay', 'background_segmentation', 'camera_analysis'],
    'gpu_worker_2': ['scene_segmentation', 'color_analysis', 'body_pose', 'age_estimation', 'content_quality', 'eye_tracking', 'cut_analysis'],
    'cpu_parallel': ['speech_transcription', 'audio_analysis', 'audio_environment', 'speech_emotion', 'temporal_flow', 'speech_flow']
}

# Deaktivierte Analyzer (Performance/Stabilit√§t)
DISABLED_ANALYZERS = [
    'face_detection', 'emotion_detection', 'facial_details',  # Ersetzt durch bessere Versionen
    'video_llava', 'blip2_video_analyzer', 'vid2seq',         # Alternative Models
    'depth_estimation', 'temporal_consistency',               # Experimentell
    # ... weitere 15 deaktivierte Analyzer
]
```

#### `configs/performance_config.py` - Performance Tuning
```python
# Frame-Sampling Konfiguration pro Analyzer
FRAME_SAMPLING = {
    'object_detection': {'interval': 10, 'batch_size': 64},   # Jeden 10. Frame, Batch 64
    'text_overlay': {'interval': 30, 'batch_size': 16},       # Jeden 30. Frame, Batch 16
    'qwen2_vl_temporal': {'interval': 60, 'batch_size': 1},   # Jeden 60. Frame, Single
    # ... weitere Analyzer-spezifische Settings
}

# GPU Memory Limits
GPU_MEMORY_LIMITS = {
    'worker_0': 16000,  # MB - Qwen2-VL braucht viel
    'worker_1': 8000,   # MB - Visuelle Analyzer
    'worker_2': 6000,   # MB - Detail Analyzer
}
```

### Environment Variables (fix_ffmpeg_env.sh)
```bash
# FFmpeg Fixes (KRITISCH!)
export OPENCV_FFMPEG_CAPTURE_OPTIONS="protocol_whitelist=file,http,https,tcp,tls"
export OPENCV_VIDEOIO_PRIORITY_BACKEND=4  # GStreamer Backend
export OPENCV_FFMPEG_MULTITHREADED=0      # Verhindert pthread crashes
export OPENCV_FFMPEG_DEBUG=1

# GPU Optimierungen
export CUDA_VISIBLE_DEVICES=0
export TF_FORCE_GPU_ALLOW_GROWTH=true
export TORCH_CUDA_ARCH_LIST="7.5"  # RTX 8000 Architecture

# Memory Pool Optimierung (80% Performance Boost!)
export PYTORCH_CUDA_ALLOC_CONF='max_split_size_mb:512,expandable_segments:True,garbage_collection_threshold:0.9'
export CUDA_LAUNCH_BLOCKING=0

# CPU Optimierung
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8

# MPS (Multi-Process Service) f√ºr maximale GPU-Auslastung
export CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps
export CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log
```

## üìä API-Dokumentation

### FastAPI Server (Port 8003)

#### Endpoints

**GET /health** - System Health Check
```bash
curl http://localhost:8003/health
```
Response:
```json
{
  "status": "healthy",
  "timestamp": "2025-07-13T07:00:00",
  "gpu": {
    "gpu_available": true,
    "gpu_name": "Quadro RTX 8000",
    "gpu_memory": {"used_mb": 2048, "total_mb": 45541, "utilization": "15.0%"}
  },
  "active_analyzers": 17,
  "parallelization": "multiprocess"
}
```

**POST /analyze** - Video Analysis
```bash
# TikTok URL Analysis
curl -X POST "http://localhost:8003/analyze" \
  -H "Content-Type: application/json" \
  -d '{"tiktok_url": "https://www.tiktok.com/@username/video/123"}'

# Local File Analysis
curl -X POST "http://localhost:8003/analyze" \
  -H "Content-Type: application/json" \
  -d '{"video_path": "/path/to/video.mp4"}'
```

#### Request Format
```json
{
  "tiktok_url": "https://www.tiktok.com/@username/video/123",  // Optional
  "video_path": "/path/to/local/video.mp4",                   // Optional
  "analyzers": ["object_detection", "qwen2_vl_temporal"],     // Optional: Specific analyzers
  "priority": 5                                               // Optional: 1-10
}
```

#### Response Format
```json
{
  "status": "success",
  "video_path": "/home/user/tiktok_videos/videos/123.mp4",
  "processing_time": 78.5,
  "successful_analyzers": 17,
  "total_analyzers": 17,
  "results_file": "/home/user/tiktok_production/results/123_analysis.json",
  "error": null
}
```

#### Error Handling
```json
{
  "status": "error",
  "error": "GPU out of memory",
  "details": "CUDA error: out of memory on GPU 0",
  "retry_possible": true,
  "suggested_action": "Wait for current analysis to complete"
}
```

### Performance Metriken

Das System tracked automatisch:
- **Processing Time**: Gesamtzeit f√ºr komplette Analyse
- **Realtime Factor**: Verh√§ltnis Processing Time zu Video Length
- **GPU Utilization**: Durchschnittliche und Peak GPU-Auslastung
- **Memory Usage**: GPU und System Memory w√§hrend Analyse
- **Cache Hit Rate**: Anteil wiederverwendeter Modelle
- **Analyzer Success Rate**: Erfolgreiche vs. fehlgeschlagene Analyzer

## üéØ Verwendung

### Einfache Video-Analyse
```bash
# 1. Starte System
cd /home/user/tiktok_production
source fix_ffmpeg_env.sh
python3 api/stable_production_api_multiprocess.py &

# 2. Analysiere TikTok Video
curl -X POST "http://localhost:8003/analyze" \
  -H "Content-Type: application/json" \
  -d '{"tiktok_url": "https://www.tiktok.com/@username/video/123"}' \
  > analysis_response.json

# 3. Pr√ºfe Ergebnis
cat analysis_response.json
```

### Batch-Verarbeitung (Mass Processing)
```bash
cd mass_processing

# Setup
pip install -r requirements.txt
python3 init_db.py

# URLs-Datei erstellen
cat > urls.txt << EOF
https://www.tiktok.com/@user1/video/123
https://www.tiktok.com/@user2/video/456
https://www.tiktok.com/@user3/video/789
EOF

# Bulk Processing starten
python3 bulk_processor.py add-urls urls.txt --priority 5
python3 bulk_processor.py process --workers 4

# Fortschritt √ºberwachen
python3 bulk_processor.py status

# Web Dashboard (optional)
python3 dashboard.py  # http://localhost:5000
```

### Monitoring w√§hrend Analyse
```bash
# Terminal 1: GPU Monitoring
watch -n 1 nvidia-smi

# Terminal 2: Echtzeit Performance Dashboard
python3 monitoring_dashboard.py

# Terminal 3: API Logs
tail -f logs/api_optimized.log

# Terminal 4: Analyse starten
curl -X POST "http://localhost:8003/analyze" \
  -H "Content-Type: application/json" \
  -d '{"tiktok_url": "YOUR_VIDEO_URL"}'
```

## ‚ö° Performance-Optimierungen

### Model Caching System
Das Model Caching System h√§lt ML-Modelle zwischen Analysen im GPU-Speicher:

**Vorher (ohne Caching):**
- Erste Analyse: 394 Sekunden
- Zweite Analyse: 394 Sekunden (Modelle werden neu geladen)

**Nachher (mit Caching):**
- Erste Analyse: 78 Sekunden (Modelle laden + Analyse)
- Zweite Analyse: 39 Sekunden (nur Analyse, Modelle aus Cache)

### GPU Memory Management
```python
# Intelligente GPU-Speicher Verwaltung
class SmartGPUManager:
    def __init__(self):
        self.memory_threshold = 0.85  # 85% GPU Memory als Limit
        
    def check_memory_before_loading(self):
        free_memory = torch.cuda.mem_get_info()[0] / 1024**2
        if free_memory < 5000:  # Weniger als 5GB frei
            self.cleanup_least_used_models()
            torch.cuda.empty_cache()
```

### Multiprocess GPU Executor
- **3 GPU Worker Processes**: Parallele Verarbeitung verschiedener Analyzer-Gruppen
- **CPU Worker Pool**: Audio-Analyzer laufen parallel auf CPU
- **Load Balancing**: Automatische Verteilung basierend auf VRAM-Anforderungen
- **Fault Tolerance**: Fehlerhafte Analyzer stoppen nicht das gesamte System

### Benchmark-Ergebnisse

| Metrik | Baseline | Optimiert | Verbesserung |
|--------|----------|-----------|--------------|
| Processing Time | 394s | 78s ‚Üí 39s | 80-90% |
| Realtime Factor | 8.02x | 1.56x ‚Üí 0.8x | 5-10x |
| GPU Utilization | 1.4% | 25-40% | 20x |
| Memory Efficiency | Fragmentiert | Pool-optimiert | Stabil |
| Cache Hit Rate | 0% | 85%+ | Neu |

## üõ†Ô∏è Wartung & Debugging

### Log-Dateien und deren Bedeutung

#### `logs/api_optimized.log` - Haupt-API Log
```
2025-07-13 07:00:00 - INFO - Worker 1: Loaded object_detection in 2.3s
2025-07-13 07:00:15 - INFO - Worker 1: Reusing cached object_detection  ‚Üê Cache Hit!
2025-07-13 07:00:30 - INFO - Worker 1: object_detection completed in 15.2s
2025-07-13 07:00:45 - WARNING - Worker 2: Low GPU memory (4.2GB), clearing cache
```

#### `logs/gpu_monitoring.csv` - GPU Metriken
```
timestamp,gpu_util,memory_used,memory_total,temperature
2025-07-13T07:00:00,25,8192,45541,65
2025-07-13T07:00:01,35,12288,45541,67
2025-07-13T07:00:02,42,15360,45541,69
```

### H√§ufige Fehler und L√∂sungen

#### CUDA Out of Memory (OOM)
```bash
# Symptom: "RuntimeError: CUDA out of memory"
# Ursache: GPU-Speicher ersch√∂pft

# L√∂sung 1: GPU Cache leeren
python3 -c "import torch; torch.cuda.empty_cache()"

# L√∂sung 2: API neu starten
pkill -f stable_production_api
source fix_ffmpeg_env.sh
python3 api/stable_production_api_multiprocess.py

# L√∂sung 3: Batch-Gr√∂√üen reduzieren (configs/performance_config.py)
```

#### FFmpeg pthread Crashes
```bash
# Symptom: "Assertion fctx->async_lock failed"
# Ursache: FFmpeg Threading-Probleme

# L√∂sung: IMMER fix_ffmpeg_env.sh laden
source fix_ffmpeg_env.sh
# Dann API starten
```

#### Langsame Performance (>5x realtime)
```bash
# √úberpr√ºfungen:
# 1. Environment korrekt geladen?
echo $PYTORCH_CUDA_ALLOC_CONF

# 2. Model Caching aktiv?
grep "Reusing cached" logs/api_optimized.log

# 3. GPU-Auslastung
nvidia-smi

# 4. Alle GPU-Worker laufen?
ps aux | grep python | grep stable_production_api
```

### Performance-Monitoring

#### Echtzeit GPU-Monitoring
```bash
# Starte Monitoring Dashboard
python3 monitoring_dashboard.py

# Output:
# Time    | GPU Usage | GPU Memory | CPU Usage | Cache Hits
# --------------------------------------------------------
#   60s   |    35.2%  |   18432MB  |    45.1%  |        12
#  120s   |    42.8%  |   22016MB  |    52.3%  |        18
```

#### Performance-Report generieren
```bash
# F√ºhre Performance-Test durch
python3 test_optimizations.py

# Generiert:
# - test_results.txt (Summary)
# - gpu_timeline.csv (GPU-Metriken √ºber Zeit)
# - optimization_test_results.json (Detaillierte Metriken)
```

### Backup-Strategie

#### Automatische t√§gliche Backups
```bash
# Erstelle Backup-Script (l√§uft t√§glich via Cron)
cat > daily_backup.sh << 'EOF'
#!/bin/bash
timestamp=$(date +%Y%m%d_%H%M%S)
backup_dir="backups/daily_$timestamp"
mkdir -p $backup_dir

# Backup kritischer Dateien
cp -r configs/ $backup_dir/
cp -r utils/ $backup_dir/
cp fix_ffmpeg_env.sh $backup_dir/
cp ml_analyzer_registry_complete.py $backup_dir/

# Komprimieren
tar -czf $backup_dir.tar.gz $backup_dir/
rm -rf $backup_dir/

echo "Backup created: $backup_dir.tar.gz"
EOF

chmod +x daily_backup.sh

# Cron Job hinzuf√ºgen (l√§uft t√§glich um 2 Uhr)
(crontab -l 2>/dev/null; echo "0 2 * * * /home/user/tiktok_production/daily_backup.sh") | crontab -
```

## üìà Erweiterungen

### Neue Analyzer hinzuf√ºgen

#### 1. Analyzer-Klasse erstellen
```python
# analyzers/my_new_analyzer.py
from analyzers.base_analyzer import GPUBatchAnalyzer

class MyNewAnalyzer(GPUBatchAnalyzer):
    def __init__(self, batch_size=8):
        super().__init__(batch_size)
        self.analyzer_name = "my_new_analyzer"
        
    def _load_model_impl(self):
        # Lade dein ML-Modell hier
        self.model = load_my_model()
        self.model.eval()
        
    def process_batch_gpu(self, frames, frame_times):
        # GPU-Batch Verarbeitung
        with torch.no_grad():
            results = self.model(frames)
        return self.format_results(results, frame_times)
```

#### 2. In Registry registrieren
```python
# ml_analyzer_registry_complete.py
from analyzers.my_new_analyzer import MyNewAnalyzer

ML_ANALYZERS = {
    # ... existing analyzers
    'my_new_analyzer': MyNewAnalyzer,
}
```

#### 3. GPU-Gruppe zuweisen
```python
# configs/gpu_groups_config.py
GPU_ANALYZER_GROUPS = {
    'gpu_worker_2': [
        # ... existing analyzers
        'my_new_analyzer',  # F√ºge zu geeignetem Worker hinzu
    ]
}
```

#### 4. Performance-Konfiguration
```python
# configs/performance_config.py
ANALYZER_TIMINGS = {
    # ... existing timings
    'my_new_analyzer': 10.0,  # Erwartete Laufzeit in Sekunden
}
```

### Model Updates

#### Qwen2-VL Model Update
```bash
# 1. Backup aktuelle Version
cp -r ~/.cache/huggingface/transformers/models--Qwen--Qwen2-VL-7B-Instruct \
   ~/model_backups/qwen2_vl_backup_$(date +%Y%m%d)

# 2. L√∂sche Cache f√ºr Neudownload
rm -rf ~/.cache/huggingface/transformers/models--Qwen--Qwen2-VL-7B-Instruct

# 3. Update Model ID in Analyzer
# analyzers/qwen2_vl_video_analyzer.py
# self.model_name = "Qwen/Qwen2-VL-7B-Instruct-v2"  # Neue Version

# 4. Teste neue Version
python3 test_analyzer_quality_v2.py
```

### Skalierung

#### Horizontal Scaling (mehrere GPUs)
```python
# configs/gpu_groups_config.py - Multi-GPU Setup
GPU_ANALYZER_GROUPS = {
    'gpu_worker_0_gpu0': ['qwen2_vl_temporal'],           # GPU 0
    'gpu_worker_1_gpu0': ['object_detection', 'text_overlay'],  # GPU 0
    'gpu_worker_0_gpu1': ['background_segmentation'],     # GPU 1
    'gpu_worker_1_gpu1': ['camera_analysis', 'scene_segmentation'],  # GPU 1
}

# Environment f√ºr Multi-GPU
export CUDA_VISIBLE_DEVICES=0,1
```

#### Vertical Scaling (mehr VRAM)
Mit mehr GPU-VRAM k√∂nnen gr√∂√üere Batch-Gr√∂√üen verwendet werden:
```python
# configs/performance_config.py
FRAME_SAMPLING = {
    'object_detection': {'batch_size': 128},  # Erh√∂ht von 64
    'text_overlay': {'batch_size': 32},       # Erh√∂ht von 16
}
```

---

## üìã Quick Reference

### Wichtigste Befehle
```bash
# System starten
source fix_ffmpeg_env.sh && python3 api/stable_production_api_multiprocess.py &

# Video analysieren
curl -X POST "http://localhost:8003/analyze" -H "Content-Type: application/json" -d '{"tiktok_url": "URL"}'

# Status pr√ºfen
curl http://localhost:8003/health

# Performance testen
python3 test_optimizations.py

# GPU √ºberwachen
watch -n 1 nvidia-smi

# System stoppen
pkill -f stable_production_api
```

### Wichtigste Dateien
- `fix_ffmpeg_env.sh` - MUSS vor jedem Start geladen werden
- `api/stable_production_api_multiprocess.py` - Production API
- `ml_analyzer_registry_complete.py` - Analyzer Registry
- `configs/gpu_groups_config.py` - GPU Worker Konfiguration

### Performance-Erwartungen
- **Erste Analyse**: ~78 Sekunden (1.56x realtime)
- **Weitere Analysen**: ~39 Sekunden (0.8x realtime)
- **GPU-Auslastung**: 25-40% w√§hrend Analyse
- **Output**: 2-3MB JSON mit vollst√§ndiger Frame-by-Frame Analyse

---

*Dieses System erreicht nahezu Echtzeit-Performance f√ºr umfassende Video-Analyse durch intelligente GPU-Optimierungen und Model Caching. Die 17 aktiven Analyzer liefern professionelle Film-Analyse-Qualit√§t in Rekordzeit.*